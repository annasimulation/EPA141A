{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Lake model: Exploring the behavior of a decision-making system\n",
    "\n",
    "Explore the lake problem, connect it to the workbench, investigate system behavior, analyze trade-offs, and learn about parallelization.\n",
    "\n",
    "See also [this general introduction to the workbench](https://waterprogramming.wordpress.com/2017/11/01/using-the-exploratory-modelling-workbench/) as a source of inspiration for completing the assignment below\n",
    "\n",
    "### Overview of this notebook\n",
    "- Learn about the Lake Problem, a decision-making example about pollution management\n",
    "  - Connect the Python implementation of the lake model to the EMA workbench\n",
    "  - Define and explore uncertainties and decision levers in the model\n",
    "- Investigate the behavior of the system under various scenarios and policies\n",
    "  - Visualize and analyze trade-offs between outcomes\n",
    "- Experiment with parallelization techniques to improve computational efficiency"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### The Lake model\n",
    "The exploratory modeling workbench includes an [examples folder](https://github.com/quaquel/EMAworkbench/tree/master/ema_workbench/examples). This folder contains a variety of examples that demonstrate the functionality of the workbench. Many of these examples have been drawn from published cases. Here, we use the Lake Problem as an example for demonstrating some of the key functionality of the workbench.\n",
    "\n",
    "We demonstrate some of the key capabilities of the exploratory modeling workbench using the Lake problem. The lake problem is a stylized and hypothetical decision problem where the population of a city has to decide on the amount of annual pollution it will put into a lake. It the pollution in the lake passes a threshold, it will suffer irreversible eutrophication (nutrient overenrichment).\n",
    "\n",
    "#### Model\n",
    "This can be modeled as a system of ordinary differential equations (ODEs) as follows:\n",
    "\n",
    "\\begin{equation}\n",
    "    X_{(t+1)}=X_t+a_t+\\frac{(X_t^q)}{(1+X_t^q )}- bX_t+\\epsilon_t\n",
    "\\end{equation}\n",
    "\n",
    "where\n",
    " - $X_t$ is the pollution at time $t$\n",
    " - $a_t$ is the rate of anthropogenic pollution at time $t$\n",
    " - $b$ is the lake’s natural removal rate\n",
    " - $q$ is the lake's natural recycling rate\n",
    " - $\\epsilon_t$ is the rate of natural pollution at time $t$.\n",
    "\n",
    "The rate of anthropogenic pollution $a_t$ is the decision variable and is somewhere between 0, and 0.1. So $a_t \\in [0,0.1]$. The natural pollution $\\epsilon_t$ is modeled, following Singh et al. (2015), as a log normal distribution with mean $\\mu$ and standard deviation $\\sigma$.\n",
    "\n",
    "\n",
    "#### Outcomes\n",
    "There are four outcomes of interest.\n",
    " 1. The first is the average concentration of phosphor in the lake.\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{phosphorus}=  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t\\in{T}} X_t \n",
    "\\end{equation}\n",
    "\n",
    "   where $\\left\\vert{T}\\right\\vert$ is the cardinality of the set of points in time.\n",
    "\n",
    " 2. The second objective is the economic benefit derived from polluting the lake. Following Singh et al. (2015), this is defined as the discounted benefit of pollution mines the costs of having a polluted lake\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{economic} = \\sum\\limits_{t \\in {T}}\\alpha a_t \\delta^t \n",
    "\\end{equation}\n",
    "\n",
    "   where $\\alpha$ is the utility derived from polluting and $\\delta$ is the discount rate. By default, $\\alpha$ is 0.04.\n",
    "\n",
    "  3. The third objective is related to the year-over-year change in the anthropogenic pollution rate.\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{inertia} =\\frac{1}{\\left\\vert{T}\\right\\vert-1} \\sum\\limits_{t=1}^{\\left\\vert{T}\\right\\vert} I(|a_{t}-a_{t-1} |>\\tau)   \n",
    "\\end{equation}\n",
    "\n",
    "   where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $\\tau$ is the threshold that is deemed undesirable, and is for illustrative purposes et to 0.2. Effectively, f_{inertia} is the fraction of years when the absolute value of the change in anthropogenic pollution is larger then $\\tau$.\n",
    "\n",
    " 4. The fourth objective is the fraction of years when the pollution in the lake is below the critical threshold.\n",
    "\n",
    "\\begin{equation}\n",
    "    f_{reliability} =  \\frac{1}{\\left\\vert{T}\\right\\vert} \\sum\\limits_{t \\in T}I(X_{t}<X_{crit} ) \n",
    "\\end{equation}\n",
    "\n",
    "   where $I$ is an indicator function that is 0 if the statement is false, and 1 if the statement is true, $X_{crit}$ is the critical threshold of pollution and is a function of both $b$ and $q$.\n",
    "\n",
    "#### Uncertainty\n",
    "The lake problem is characterized by both stochastic uncertainty and deep uncertainty.\n",
    " - The stochastic uncertainty arises from the natural inflow. To reduce this stochastic uncertainty, multiple replications are performed and the average over the replications is taken.\n",
    " - Deep uncertainty is presented by uncertainty about the mean $\\mu$ and standard deviation $\\sigma$ of the lognormal distribution characterizing the natural inflow, the natural removal rate of the lake $\\beta$, the natural recycling rate of the lake $q$, and the discount rate $\\delta$. The table below specifies the ranges for the deeply uncertain factors, as well as their best estimate or default values."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Assignment\n",
    "_If you at any moment get stuck on this assignment, the [General Introduction](https://emaworkbench.readthedocs.io/en/latest/indepth_tutorial/general-introduction.html) of the EMAworkbench is a good source of inspiration._\n",
    "\n",
    "1. Given the Python implementation of the lake problem in [`lakemodel_function.py`](lakemodel_function.py), adapt this code and connect it to the workbench.\n",
    "\n",
    "For the uncertainties, use the following table\n",
    "\n",
    "|Parameter\t|Range\t        |Default value|\n",
    "|-----------|--------------:|------------:|\n",
    "|$\\mu$    \t|0.01 – 0.05\t|0.02         |\n",
    "|$\\sigma$\t|0.001 – 0.005 \t|0.0017       |\n",
    "|$b$      \t|0.1 – 0.45\t    |0.42         |\n",
    "|$q$\t    |2 – 4.5\t    |2            |\n",
    "|$\\delta$\t|0.93 – 0.99\t|0.98         |\n",
    "\n",
    "For now, assume that for each year a release decision is made. The release is between 0 and 0.1. Carefully look at line 24 in `lakemodel_function.py` to identify the name to use for each lever."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T15:20:46.585394300Z",
     "start_time": "2024-05-05T15:20:46.565744900Z"
    }
   },
   "outputs": [],
   "source": [
    "from lakemodel_function import lake_problem\n",
    "\n",
    "# Instantiate the model\n",
    "from ema_workbench import Model, RealParameter, TimeSeriesOutcome\n",
    "\n",
    "model = Model('lake', function=lake_problem)\n",
    "\n",
    "model.uncertainties = [RealParameter('b', 0.1, 0.45, default=0.42),\n",
    "                       RealParameter('delta', 0.93, 0.99, default= 0.98),\n",
    "                       RealParameter('mean',0.01,0.05, default= 0.02),\n",
    "                       RealParameter('stdev',0.001,0.005, default= 0.0017),\n",
    "                       RealParameter('q', 2, 4.5, default= 2)]\n",
    "\n",
    "model.outcomes = [TimeSeriesOutcome('max_P'),\n",
    "                  TimeSeriesOutcome('utility'),\n",
    "                  TimeSeriesOutcome('inertia'),\n",
    "                  TimeSeriesOutcome('reliability')]\n",
    "\n",
    "# Specify uncertainties\n",
    "\n",
    "\n",
    "# Set levers, one for each time step\n",
    "\n",
    "\n",
    "# Specify outcomes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Explore the behavior of the system in the absence of any release using 1000 scenarios, and the default sampling approach.\n",
    "    * visualize the outcomes of interest, are there any apparent trade-offs?\n",
    "    * can you visually identify the uncertainties that drive system behavior?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-05T15:21:57.143104800Z",
     "start_time": "2024-05-05T15:21:56.938008800Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|                                                 | 0/1000 [00:00<?, ?it/s]\u001B[Alake_problem() got an unexpected keyword argument 'beta'\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Joost\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py\", line 92, in run_experiment\n",
      "    model.run_model(scenario, policy)\n",
      "  File \"C:\\Users\\Joost\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 153, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Joost\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 347, in run_model\n",
      "    outputs = self.run_experiment(experiment)\n",
      "  File \"C:\\Users\\Joost\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py\", line 153, in wrapper\n",
      "    res = func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Joost\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\model.py\", line 400, in run_experiment\n",
      "    model_output = self.function(**experiment)\n",
      "TypeError: lake_problem() got an unexpected keyword argument 'beta'\n"
     ]
    },
    {
     "ename": "EMAError",
     "evalue": "Exception in run_model\nCaused by: TypeError: lake_problem() got an unexpected keyword argument 'beta'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py:92\u001B[0m, in \u001B[0;36mExperimentRunner.run_experiment\u001B[1;34m(self, experiment)\u001B[0m\n\u001B[0;32m     91\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 92\u001B[0m     \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscenario\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpolicy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m CaseError \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001B[0m, in \u001B[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 153\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    154\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted calling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\model.py:347\u001B[0m, in \u001B[0;36mSingleReplication.run_model\u001B[1;34m(self, scenario, policy)\u001B[0m\n\u001B[0;32m    345\u001B[0m experiment \u001B[38;5;241m=\u001B[39m ExperimentReplication(scenario, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpolicy, constants)\n\u001B[1;32m--> 347\u001B[0m outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moutcomes_output \u001B[38;5;241m=\u001B[39m outputs\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001B[0m, in \u001B[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    152\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 153\u001B[0m res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    154\u001B[0m logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted calling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\model.py:400\u001B[0m, in \u001B[0;36mBaseModel.run_experiment\u001B[1;34m(self, experiment)\u001B[0m\n\u001B[0;32m    393\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Method for running an instantiated model structure.\u001B[39;00m\n\u001B[0;32m    394\u001B[0m \n\u001B[0;32m    395\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    398\u001B[0m \n\u001B[0;32m    399\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m--> 400\u001B[0m model_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mexperiment)\n\u001B[0;32m    402\u001B[0m \u001B[38;5;66;03m# TODO: might it be possible to somehow abstract this\u001B[39;00m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;66;03m# perhaps expose a get_data on modelInterface?\u001B[39;00m\n\u001B[0;32m    404\u001B[0m \u001B[38;5;66;03m# different connectors can than implement only this\u001B[39;00m\n\u001B[0;32m    405\u001B[0m \u001B[38;5;66;03m# get method\u001B[39;00m\n",
      "\u001B[1;31mTypeError\u001B[0m: lake_problem() got an unexpected keyword argument 'beta'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mEMAError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[6], line 5\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mema_workbench\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SequentialEvaluator\n\u001B[0;32m      4\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m SequentialEvaluator(model) \u001B[38;5;28;01mas\u001B[39;00m evaluator:\n\u001B[1;32m----> 5\u001B[0m     experiments, outcomes \u001B[38;5;241m=\u001B[39m \u001B[43mevaluator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mperform_experiments\u001B[49m\u001B[43m(\u001B[49m\u001B[43mscenarios\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1000\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:193\u001B[0m, in \u001B[0;36mBaseEvaluator.perform_experiments\u001B[1;34m(self, scenarios, policies, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, combine, **kwargs)\u001B[0m\n\u001B[0;32m    172\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mperform_experiments\u001B[39m(\n\u001B[0;32m    173\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    174\u001B[0m     scenarios\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    185\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    186\u001B[0m ):\n\u001B[0;32m    187\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"convenience method for performing experiments.\u001B[39;00m\n\u001B[0;32m    188\u001B[0m \n\u001B[0;32m    189\u001B[0m \u001B[38;5;124;03m    is forwarded to :func:perform_experiments, with evaluator and\u001B[39;00m\n\u001B[0;32m    190\u001B[0m \u001B[38;5;124;03m    models arguments added in.\u001B[39;00m\n\u001B[0;32m    191\u001B[0m \n\u001B[0;32m    192\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 193\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m perform_experiments(\n\u001B[0;32m    194\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_msis,\n\u001B[0;32m    195\u001B[0m         scenarios\u001B[38;5;241m=\u001B[39mscenarios,\n\u001B[0;32m    196\u001B[0m         policies\u001B[38;5;241m=\u001B[39mpolicies,\n\u001B[0;32m    197\u001B[0m         evaluator\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m    198\u001B[0m         reporting_interval\u001B[38;5;241m=\u001B[39mreporting_interval,\n\u001B[0;32m    199\u001B[0m         reporting_frequency\u001B[38;5;241m=\u001B[39mreporting_frequency,\n\u001B[0;32m    200\u001B[0m         uncertainty_union\u001B[38;5;241m=\u001B[39muncertainty_union,\n\u001B[0;32m    201\u001B[0m         lever_union\u001B[38;5;241m=\u001B[39mlever_union,\n\u001B[0;32m    202\u001B[0m         outcome_union\u001B[38;5;241m=\u001B[39moutcome_union,\n\u001B[0;32m    203\u001B[0m         uncertainty_sampling\u001B[38;5;241m=\u001B[39muncertainty_sampling,\n\u001B[0;32m    204\u001B[0m         lever_sampling\u001B[38;5;241m=\u001B[39mlever_sampling,\n\u001B[0;32m    205\u001B[0m         callback\u001B[38;5;241m=\u001B[39mcallback,\n\u001B[0;32m    206\u001B[0m         combine\u001B[38;5;241m=\u001B[39mcombine,\n\u001B[0;32m    207\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m    208\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:406\u001B[0m, in \u001B[0;36mperform_experiments\u001B[1;34m(models, scenarios, policies, evaluator, reporting_interval, reporting_frequency, uncertainty_union, lever_union, outcome_union, uncertainty_sampling, lever_sampling, callback, return_callback, combine, log_progress, **kwargs)\u001B[0m\n\u001B[0;32m    403\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m evaluator:\n\u001B[0;32m    404\u001B[0m     evaluator \u001B[38;5;241m=\u001B[39m SequentialEvaluator(models)\n\u001B[1;32m--> 406\u001B[0m evaluator\u001B[38;5;241m.\u001B[39mevaluate_experiments(scenarios, policies, callback, combine\u001B[38;5;241m=\u001B[39mcombine, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    408\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m callback\u001B[38;5;241m.\u001B[39mi \u001B[38;5;241m!=\u001B[39m nr_of_exp:\n\u001B[0;32m    409\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m EMAError(\n\u001B[0;32m    410\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSome fatal error has occurred while running the experiments, not all runs have completed. Expected \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnr_of_exp\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mcallback\u001B[38;5;241m.\u001B[39mi\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    411\u001B[0m     )\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\evaluators.py:291\u001B[0m, in \u001B[0;36mSequentialEvaluator.evaluate_experiments\u001B[1;34m(self, scenarios, policies, callback, combine)\u001B[0m\n\u001B[0;32m    288\u001B[0m runner \u001B[38;5;241m=\u001B[39m ExperimentRunner(models)\n\u001B[0;32m    290\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m experiment \u001B[38;5;129;01min\u001B[39;00m ex_gen:\n\u001B[1;32m--> 291\u001B[0m     outcomes \u001B[38;5;241m=\u001B[39m \u001B[43mrunner\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_experiment\u001B[49m\u001B[43m(\u001B[49m\u001B[43mexperiment\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    292\u001B[0m     callback(experiment, outcomes)\n\u001B[0;32m    293\u001B[0m runner\u001B[38;5;241m.\u001B[39mcleanup()\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\util\\ema_logging.py:153\u001B[0m, in \u001B[0;36mmethod_logger.<locals>.real_decorator.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;129m@wraps\u001B[39m(func)\n\u001B[0;32m    149\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwrapper\u001B[39m(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    150\u001B[0m     \u001B[38;5;66;03m# hack, because log is applied to methods, we can get\u001B[39;00m\n\u001B[0;32m    151\u001B[0m     \u001B[38;5;66;03m# object instance as first arguments in args\u001B[39;00m\n\u001B[0;32m    152\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcalling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m--> 153\u001B[0m     res \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    154\u001B[0m     logger\u001B[38;5;241m.\u001B[39mdebug(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcompleted calling \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m on \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mclassname\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    155\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m res\n",
      "File \u001B[1;32m~\\PycharmProjects\\venv\\lib\\site-packages\\ema_workbench\\em_framework\\experiment_runner.py:108\u001B[0m, in \u001B[0;36mExperimentRunner.run_experiment\u001B[1;34m(self, experiment)\u001B[0m\n\u001B[0;32m    102\u001B[0m     \u001B[38;5;66;03m#             exception = traceback.print_exc()\u001B[39;00m\n\u001B[0;32m    103\u001B[0m     \u001B[38;5;66;03m#             if exception:\u001B[39;00m\n\u001B[0;32m    104\u001B[0m     \u001B[38;5;66;03m#                 sys.stderr.write(exception)\u001B[39;00m\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;66;03m#                 sys.stderr.write(\"\\n\")\u001B[39;00m\n\u001B[0;32m    107\u001B[0m     errortype \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mtype\u001B[39m(e)\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\n\u001B[1;32m--> 108\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m EMAError(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException in run_model\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mCaused by: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00merrortype\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    110\u001B[0m outcomes \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39moutcomes_output\n\u001B[0;32m    111\u001B[0m model\u001B[38;5;241m.\u001B[39mreset_model()\n",
      "\u001B[1;31mEMAError\u001B[0m: Exception in run_model\nCaused by: TypeError: lake_problem() got an unexpected keyword argument 'beta'"
     ]
    }
   ],
   "source": [
    "# Hint: A great moment to take another look at the examples!\n",
    "from ema_workbench import SequentialEvaluator\n",
    "\n",
    "with SequentialEvaluator(model) as evaluator:\n",
    "    experiments, outcomes = evaluator.perform_experiments(scenarios=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Explore the behavior of the system over 1000 scenarios for 4 randomly sampled candidate strategies.\n",
    "    * visualize the outcomes of interest\n",
    "    * what can you say about how the release decision influences the system?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:56:55.068135Z",
     "end_time": "2023-04-07T13:56:55.068641Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. If you have not used parallelization in the foregoing, try to adapt your code to use parallelization. The workbench comes with two evaluators for parallelization. The `MultiProcessingingEvaluator` and the `IpyparallelEvaluator`. When can you use each? Adapt your code from above and sue the `MultiProcessingingEvaluator`. Use the `time` or `timeit` library to check how much faster the computation for 1000 scenarios completes.\n",
    "\n",
    "#### A note on parallelization in Jupyter notebooks\n",
    "Using multiprocessing within a Jupyter notebook is tricky. On Linux it will work in general just fine. On a Mac it depends on the version of macOS and the version of Python. If you are on the latest version of macOS in combination with Python 3.8, it might work but no guarantees. On older versions of Python it should work fine. On Windows it is always a problem.\n",
    "\n",
    "The underlying explanation is quite technical. It has to do with how your operating system creates the additional python processes. On Windows, and the latest version of macOS in combination with Python 3.8. A completely new Python process is spawned. This new process does **not** inherit what is defined in memory of the parent process. The new child process will try to replicate what is in memory of the parent process by executing many of the import statements that have also been executed within the python process. Thus, if you define a model in the main process, it is not guaranteed to be known in the child processes. This is in particular true if you define the model within a jupyter notebook. Then the child processes will **never** know this function. Within jupyter notebooks, therefore, the best practice is to define your model within a `.py` file and import this `.py` file into the notebook. Now, each of the child processes will also execute this import statement and thus know the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-07T13:56:55.071076Z",
     "end_time": "2023-04-07T13:56:55.071581Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Conclusion\n",
    "..."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
